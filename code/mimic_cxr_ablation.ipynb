{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1pRfsPQlDWevcT3yFRac9jUT8RginW9m3",
      "authorship_tag": "ABX9TyOSzdWZUbkby6iktkhAPm7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeet1912/florence-2_ablationStudy/blob/main/code/mimic_cxr_ablation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yrq0KZJpo5xl",
        "outputId": "388f92b5-bb00-44cb-c024-9db40a941c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting gcsfs\n",
            "  Downloading gcsfs-2025.7.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (3.12.15)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (4.4.2)\n",
            "Collecting fsspec==2025.7.0 (from gcsfs)\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.20.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.14.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.3.1)\n",
            "Downloading gcsfs-2025.7.0-py2.py3-none-any.whl (36 kB)\n",
            "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, gcsfs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: gcsfs\n",
            "    Found existing installation: gcsfs 2025.3.0\n",
            "    Uninstalling gcsfs-2025.3.0:\n",
            "      Successfully uninstalled gcsfs-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.7.0 gcsfs-2025.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fsspec",
                  "gcsfs"
                ]
              },
              "id": "3e5152f2d45141ac859f641b83fa08a8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade gcsfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rQ59GbBNwvj",
        "outputId": "2b9119d7-cecd-49c3-f171-a50239a08917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.38.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.25.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.8.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iterative-stratification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34c7An9Rwrb5",
        "outputId": "09b05785-d28c-4822-86d8-22841eae046a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from iterative-stratification) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
            "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn6Qdg0xyJo-",
        "outputId": "bb054241-d43c-4ee8-9f02-4ed50838fc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.7.0\n",
            "    Uninstalling fsspec-2025.7.0:\n",
            "      Successfully uninstalled fsspec-2025.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.7.0 requires fsspec==2025.7.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.23.4 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed evaluate-0.4.5 fsspec-2025.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIP9ScA13mCq",
        "outputId": "a3af0395-296d-43c2-f983-f311b2653b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.54.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.34.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.8.3)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gcsfs\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import io\n",
        "import os\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import itertools\n",
        "from evaluate import load\n",
        "import gc\n",
        "import time\n",
        "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "from google.cloud import storage\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"colorblind\")"
      ],
      "metadata": {
        "id": "Z6FUx7DyKtZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942204b6-695a-4bae-f39a-08d09b6a0ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CXR(Dataset):\n",
        "  def __init__(self, dataframe, processor, max_length):\n",
        "    super().__init__()\n",
        "    self.dataframe = dataframe.reset_index(drop=True)\n",
        "    self.processor = processor\n",
        "    self.max_length = max_length\n",
        "    self.prompt = \"List pathalogical findings for this chest X-ray:\"\n",
        "    self.storage_client = storage.Client(project='ablation-study')\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def _loadImage(self,subject_id, study_id, dicom_id):\n",
        "    try:\n",
        "      bucket_name = \"mimic-cxr-jpg-2.1.0.physionet.org\"\n",
        "      image_path = f\"files/p{subject_id[:2]}/p{subject_id}/s{study_id}/{dicom_id}.jpg\"\n",
        "      bucket = self.storage_client.bucket(bucket_name, user_project='ablation-study')\n",
        "      blob = bucket.blob(image_path)\n",
        "      image_bytes = blob.download_as_bytes()\n",
        "      image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n",
        "      return image\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading image {image_path}: {str(e)}\")\n",
        "      return None # Return None if image loading fails\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    row = self.dataframe.iloc[index]\n",
        "    miniReport = str(row['mini_report'])\n",
        "    subject = str(row['subject_id'])\n",
        "    study = str(row['study_id'])\n",
        "    dicom = str(row['dicom_id'])\n",
        "    image = self._loadImage(subject_id=subject,study_id=study,dicom_id=dicom)\n",
        "    inputs = self.processor(images=image, text=self.prompt, return_tensors=\"pt\", padding=\"max_length\",\n",
        "                            truncation=True, max_length=self.max_length)\n",
        "    labels = self.processor.tokenizer(miniReport, return_tensors=\"pt\", padding=\"max_length\",\n",
        "                                      truncation=True, max_length=self.max_length)[\"input_ids\"]\n",
        "\n",
        "    return {\n",
        "      \"pixel_values\": inputs[\"pixel_values\"],  # Shape: [1, 3, H, W]\n",
        "      \"input_ids\": inputs[\"input_ids\"],        # Shape: [1, max_length]\n",
        "      \"attention_mask\": inputs[\"attention_mask\"],  # Shape: [1, max_length]\n",
        "      \"labels\": labels                         # Shape: [1, max_length]\n",
        "    }"
      ],
      "metadata": {
        "id": "xLG7hYueT1Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(\"microsoft/git-base\")"
      ],
      "metadata": {
        "id": "gZDMS387yud0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/ds677_ablationStudy/train_split.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/ds677_ablationStudy/test_split.csv')\n",
        "val_df = pd.read_csv('/content/drive/MyDrive/ds677_ablationStudy/val_split.csv')\n",
        "\n",
        "max_length = max(len(processor.tokenizer.encode(report)) for report in train_df['mini_report'])\n",
        "print(f\"Max length of mini-reports: {max_length}\")\n",
        "\n",
        "train_dataset = CXR(train_df, processor, max_length)\n",
        "val_dataset = CXR(val_df, processor, max_length)\n",
        "test_dataset = CXR(test_df, processor, max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ymi9N_y10l",
        "outputId": "696dc64e-8539-4958-e4a8-6f446e076e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of mini-reports: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['pixel_values'].shape)\n",
        "print(train_dataset[0]['input_ids'].shape)\n",
        "print(train_dataset[0]['attention_mask'].shape)\n",
        "print(train_dataset[0]['labels'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXcl1XeuzFfx",
        "outputId": "b9da40a8-1a5d-4548-bb1b-1a16fbd65fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 92])\n",
            "torch.Size([1, 92])\n",
            "torch.Size([1, 92])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/ds677_ablationStudy/results'"
      ],
      "metadata": {
        "id": "UYIiBhE8zPLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")"
      ],
      "metadata": {
        "id": "FYyw_Wfe03Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJfqR-5y8qKq",
        "outputId": "70e102c8-4112-452f-f1a3-6fbc3cabebc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    pixel_values = torch.cat([item[\"pixel_values\"] for item in batch], dim=0)  # [batch_size, 3, H, W]\n",
        "    input_ids = torch.cat([item[\"input_ids\"] for item in batch], dim=0)        # [batch_size, max_length]\n",
        "    attention_mask = torch.cat([item[\"attention_mask\"] for item in batch], dim=0)  # [batch_size, max_length]\n",
        "    labels = torch.cat([item[\"labels\"] for item in batch], dim=0)               # [batch_size, max_length]\n",
        "\n",
        "    #print(f\"Batch shapes: pixel_values={pixel_values.shape}, input_ids={input_ids.shape}, \"\n",
        "    #      f\"attention_mask={attention_mask.shape}, labels={labels.shape}\")\n",
        "\n",
        "    return {\n",
        "        \"pixel_values\": pixel_values,\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels\n",
        "    }"
      ],
      "metadata": {
        "id": "cbW4bQ9VJtyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base\")"
      ],
      "metadata": {
        "id": "bFTGc_BMLwrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in model.named_modules():\n",
        "  print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71O_HHP3L1pv",
        "outputId": "4a44642e-73ab-46d6-e8b2-83f61a7b3a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "git\n",
            "git.embeddings\n",
            "git.embeddings.word_embeddings\n",
            "git.embeddings.position_embeddings\n",
            "git.embeddings.LayerNorm\n",
            "git.embeddings.dropout\n",
            "git.image_encoder\n",
            "git.image_encoder.vision_model\n",
            "git.image_encoder.vision_model.embeddings\n",
            "git.image_encoder.vision_model.embeddings.patch_embedding\n",
            "git.image_encoder.vision_model.embeddings.position_embedding\n",
            "git.image_encoder.vision_model.pre_layrnorm\n",
            "git.image_encoder.vision_model.encoder\n",
            "git.image_encoder.vision_model.encoder.layers\n",
            "git.image_encoder.vision_model.encoder.layers.0\n",
            "git.image_encoder.vision_model.encoder.layers.0.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.0.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.0.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.0.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.0.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.0.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.0.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.0.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.0.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.0.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.0.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.1\n",
            "git.image_encoder.vision_model.encoder.layers.1.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.1.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.1.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.1.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.1.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.1.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.1.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.1.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.1.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.1.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.1.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.2\n",
            "git.image_encoder.vision_model.encoder.layers.2.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.2.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.2.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.2.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.2.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.2.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.2.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.2.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.2.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.2.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.2.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.3\n",
            "git.image_encoder.vision_model.encoder.layers.3.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.3.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.3.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.3.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.3.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.3.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.3.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.3.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.3.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.3.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.3.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.4\n",
            "git.image_encoder.vision_model.encoder.layers.4.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.4.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.4.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.4.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.4.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.4.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.4.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.4.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.4.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.4.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.4.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.5\n",
            "git.image_encoder.vision_model.encoder.layers.5.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.5.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.5.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.5.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.5.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.5.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.5.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.5.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.5.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.5.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.5.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.6\n",
            "git.image_encoder.vision_model.encoder.layers.6.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.6.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.6.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.6.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.6.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.6.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.6.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.6.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.6.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.6.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.6.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.7\n",
            "git.image_encoder.vision_model.encoder.layers.7.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.7.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.7.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.7.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.7.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.7.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.7.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.7.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.7.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.7.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.7.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.8\n",
            "git.image_encoder.vision_model.encoder.layers.8.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.8.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.8.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.8.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.8.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.8.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.8.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.8.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.8.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.8.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.8.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.9\n",
            "git.image_encoder.vision_model.encoder.layers.9.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.9.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.9.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.9.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.9.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.9.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.9.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.9.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.9.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.9.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.9.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.10\n",
            "git.image_encoder.vision_model.encoder.layers.10.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.10.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.10.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.10.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.10.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.10.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.10.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.10.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.10.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.10.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.10.layer_norm2\n",
            "git.image_encoder.vision_model.encoder.layers.11\n",
            "git.image_encoder.vision_model.encoder.layers.11.self_attn\n",
            "git.image_encoder.vision_model.encoder.layers.11.self_attn.k_proj\n",
            "git.image_encoder.vision_model.encoder.layers.11.self_attn.v_proj\n",
            "git.image_encoder.vision_model.encoder.layers.11.self_attn.q_proj\n",
            "git.image_encoder.vision_model.encoder.layers.11.self_attn.out_proj\n",
            "git.image_encoder.vision_model.encoder.layers.11.layer_norm1\n",
            "git.image_encoder.vision_model.encoder.layers.11.mlp\n",
            "git.image_encoder.vision_model.encoder.layers.11.mlp.activation_fn\n",
            "git.image_encoder.vision_model.encoder.layers.11.mlp.fc1\n",
            "git.image_encoder.vision_model.encoder.layers.11.mlp.fc2\n",
            "git.image_encoder.vision_model.encoder.layers.11.layer_norm2\n",
            "git.image_encoder.vision_model.post_layernorm\n",
            "git.encoder\n",
            "git.encoder.layer\n",
            "git.encoder.layer.0\n",
            "git.encoder.layer.0.attention\n",
            "git.encoder.layer.0.attention.self\n",
            "git.encoder.layer.0.attention.self.query\n",
            "git.encoder.layer.0.attention.self.key\n",
            "git.encoder.layer.0.attention.self.value\n",
            "git.encoder.layer.0.attention.self.dropout\n",
            "git.encoder.layer.0.attention.output\n",
            "git.encoder.layer.0.attention.output.dense\n",
            "git.encoder.layer.0.attention.output.LayerNorm\n",
            "git.encoder.layer.0.attention.output.dropout\n",
            "git.encoder.layer.0.intermediate\n",
            "git.encoder.layer.0.intermediate.dense\n",
            "git.encoder.layer.0.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.0.output\n",
            "git.encoder.layer.0.output.dense\n",
            "git.encoder.layer.0.output.LayerNorm\n",
            "git.encoder.layer.0.output.dropout\n",
            "git.encoder.layer.1\n",
            "git.encoder.layer.1.attention\n",
            "git.encoder.layer.1.attention.self\n",
            "git.encoder.layer.1.attention.self.query\n",
            "git.encoder.layer.1.attention.self.key\n",
            "git.encoder.layer.1.attention.self.value\n",
            "git.encoder.layer.1.attention.self.dropout\n",
            "git.encoder.layer.1.attention.output\n",
            "git.encoder.layer.1.attention.output.dense\n",
            "git.encoder.layer.1.attention.output.LayerNorm\n",
            "git.encoder.layer.1.attention.output.dropout\n",
            "git.encoder.layer.1.intermediate\n",
            "git.encoder.layer.1.intermediate.dense\n",
            "git.encoder.layer.1.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.1.output\n",
            "git.encoder.layer.1.output.dense\n",
            "git.encoder.layer.1.output.LayerNorm\n",
            "git.encoder.layer.1.output.dropout\n",
            "git.encoder.layer.2\n",
            "git.encoder.layer.2.attention\n",
            "git.encoder.layer.2.attention.self\n",
            "git.encoder.layer.2.attention.self.query\n",
            "git.encoder.layer.2.attention.self.key\n",
            "git.encoder.layer.2.attention.self.value\n",
            "git.encoder.layer.2.attention.self.dropout\n",
            "git.encoder.layer.2.attention.output\n",
            "git.encoder.layer.2.attention.output.dense\n",
            "git.encoder.layer.2.attention.output.LayerNorm\n",
            "git.encoder.layer.2.attention.output.dropout\n",
            "git.encoder.layer.2.intermediate\n",
            "git.encoder.layer.2.intermediate.dense\n",
            "git.encoder.layer.2.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.2.output\n",
            "git.encoder.layer.2.output.dense\n",
            "git.encoder.layer.2.output.LayerNorm\n",
            "git.encoder.layer.2.output.dropout\n",
            "git.encoder.layer.3\n",
            "git.encoder.layer.3.attention\n",
            "git.encoder.layer.3.attention.self\n",
            "git.encoder.layer.3.attention.self.query\n",
            "git.encoder.layer.3.attention.self.key\n",
            "git.encoder.layer.3.attention.self.value\n",
            "git.encoder.layer.3.attention.self.dropout\n",
            "git.encoder.layer.3.attention.output\n",
            "git.encoder.layer.3.attention.output.dense\n",
            "git.encoder.layer.3.attention.output.LayerNorm\n",
            "git.encoder.layer.3.attention.output.dropout\n",
            "git.encoder.layer.3.intermediate\n",
            "git.encoder.layer.3.intermediate.dense\n",
            "git.encoder.layer.3.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.3.output\n",
            "git.encoder.layer.3.output.dense\n",
            "git.encoder.layer.3.output.LayerNorm\n",
            "git.encoder.layer.3.output.dropout\n",
            "git.encoder.layer.4\n",
            "git.encoder.layer.4.attention\n",
            "git.encoder.layer.4.attention.self\n",
            "git.encoder.layer.4.attention.self.query\n",
            "git.encoder.layer.4.attention.self.key\n",
            "git.encoder.layer.4.attention.self.value\n",
            "git.encoder.layer.4.attention.self.dropout\n",
            "git.encoder.layer.4.attention.output\n",
            "git.encoder.layer.4.attention.output.dense\n",
            "git.encoder.layer.4.attention.output.LayerNorm\n",
            "git.encoder.layer.4.attention.output.dropout\n",
            "git.encoder.layer.4.intermediate\n",
            "git.encoder.layer.4.intermediate.dense\n",
            "git.encoder.layer.4.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.4.output\n",
            "git.encoder.layer.4.output.dense\n",
            "git.encoder.layer.4.output.LayerNorm\n",
            "git.encoder.layer.4.output.dropout\n",
            "git.encoder.layer.5\n",
            "git.encoder.layer.5.attention\n",
            "git.encoder.layer.5.attention.self\n",
            "git.encoder.layer.5.attention.self.query\n",
            "git.encoder.layer.5.attention.self.key\n",
            "git.encoder.layer.5.attention.self.value\n",
            "git.encoder.layer.5.attention.self.dropout\n",
            "git.encoder.layer.5.attention.output\n",
            "git.encoder.layer.5.attention.output.dense\n",
            "git.encoder.layer.5.attention.output.LayerNorm\n",
            "git.encoder.layer.5.attention.output.dropout\n",
            "git.encoder.layer.5.intermediate\n",
            "git.encoder.layer.5.intermediate.dense\n",
            "git.encoder.layer.5.intermediate.intermediate_act_fn\n",
            "git.encoder.layer.5.output\n",
            "git.encoder.layer.5.output.dense\n",
            "git.encoder.layer.5.output.LayerNorm\n",
            "git.encoder.layer.5.output.dropout\n",
            "git.visual_projection\n",
            "git.visual_projection.visual_projection\n",
            "git.visual_projection.visual_projection.0\n",
            "git.visual_projection.visual_projection.1\n",
            "output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target modules for LoRA\n",
        "vision_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc1\", \"fc2\"]\n",
        "text_modules = [\"query\", \"key\", \"value\", \"dense\"]\n",
        "\n",
        "# Ablation configurations\n",
        "ablation_configs = [\n",
        "    {\"name\": \"lora_vision_only\", \"target_modules\": vision_modules},\n",
        "    {\"name\": \"lora_text_only\", \"target_modules\": text_modules},\n",
        "]"
      ],
      "metadata": {
        "id": "XHRCKS4H8rSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/ds677_ablationStudy/results/lora_target_modules\",\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=1e-5,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=1,  # Save only the best model\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    report_to=\"none\",\n",
        "    lr_scheduler_type=\"reduce_lr_on_plateau\",\n",
        "    optim=\"adamw_torch\",\n",
        "    label_names=[\"labels\"]\n",
        ")\n",
        "\n",
        "bleu = load(\"bleu\")\n",
        "\n",
        "def evaluate_model(model, test_loader, processor, max_length, device):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_samples = 0\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            batch_size_actual = batch[\"pixel_values\"].size(0)\n",
        "            test_loss += loss.item() * batch_size_actual\n",
        "            test_samples += batch_size_actual\n",
        "\n",
        "            pixel_values = batch[\"pixel_values\"]\n",
        "            input_ids = batch[\"input_ids\"]\n",
        "            generated_ids = model.generate(pixel_values=pixel_values, input_ids=input_ids,\n",
        "                                         max_length=max_length)\n",
        "            generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "            predictions.extend([text.replace(\"List pathalogical findings for this chest X-ray:\", \"\").strip() for text in generated_texts])\n",
        "\n",
        "            label_ids = batch[\"labels\"]\n",
        "            reference_texts = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "            references.extend(reference_texts)\n",
        "\n",
        "    avg_test_loss = test_loss / test_samples\n",
        "    bleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
        "    return avg_test_loss, bleu_score[\"bleu\"]"
      ],
      "metadata": {
        "id": "idBJse469tLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for config in ablation_configs:\n",
        "    print(f\"\\nRunning ablation experiment: {config['name']}\")\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base\")\n",
        "    processor = AutoProcessor.from_pretrained(\"microsoft/git-base\")\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=8,\n",
        "        lora_alpha=16,\n",
        "        target_modules=config[\"target_modules\"],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\"\n",
        "    )\n",
        "    peft_model = get_peft_model(model, lora_config)\n",
        "    peft_model.to(device)\n",
        "    peft_model.print_trainable_parameters()\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "\n",
        "    # Trainer with label_names\n",
        "    trainer = Trainer(\n",
        "        model=peft_model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=collate_fn,\n",
        "    )\n",
        "\n",
        "    # Track memory and time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train using Trainer\n",
        "    train_result = trainer.train()\n",
        "\n",
        "    # Extract losses from trainer logs\n",
        "    train_losses = [log[\"loss\"] for log in trainer.state.log_history if \"loss\" in log]\n",
        "    val_losses = [log[\"eval_loss\"] for log in trainer.state.log_history if \"eval_loss\" in log]\n",
        "\n",
        "    # Memory usage (average over epochs)\n",
        "    memory_usage = []\n",
        "    for epoch in range(10):\n",
        "        memory = torch.cuda.memory_allocated(device) / 1024**2 if device.type == \"cuda\" else torch.mps.current_allocated_memory() / 1024**2\n",
        "        memory_usage.append(memory)\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_loss, bleu_score = evaluate_model(peft_model, test_loader, processor, max_length, device)\n",
        "\n",
        "    results.append({\n",
        "        \"experiment\": config[\"name\"],\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"memory_usage_MB\": memory_usage,\n",
        "        \"training_time_seconds\": training_time,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"bleu_score\": bleu_score,\n",
        "        \"trainable_parameters\": peft_model.get_nb_trainable_parameters()[0]\n",
        "    })\n",
        "\n",
        "    del peft_model\n",
        "    del model\n",
        "    torch.cuda.empty_cache() if device.type == \"cuda\" else torch.mps.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Save results\n",
        "folder_path = '/content/drive/MyDrive/ds677_ablationStudy/results'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(os.path.join(folder_path, 'lora_target_modules_ablation_results.csv'), index=False)\n",
        "print(\"\\nAblation Study Results (Target Modules):\")\n",
        "print(results_df[[\"experiment\", \"test_loss\", \"bleu_score\", \"training_time_seconds\", \"trainable_parameters\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "CnqGFYu8-TgW",
        "outputId": "9131b832-441b-4312-b813-57b16a55f57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running ablation experiment: lora_vision_only\n",
            "trainable params: 1,327,104 || all params: 177,946,170 || trainable%: 0.7458\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2236' max='4170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2236/4170 10:31:11 < 9:06:25, 0.06 it/s, Epoch 2.68/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>9.105000</td>\n",
              "      <td>8.740946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>8.681500</td>\n",
              "      <td>8.604371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2242' max='4170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2242/4170 10:32:46 < 9:04:38, 0.06 it/s, Epoch 2.69/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>9.105000</td>\n",
              "      <td>8.740946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>8.681500</td>\n",
              "      <td>8.604371</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OVD6T5KLl2q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}