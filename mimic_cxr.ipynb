{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7B4mtckHpo0d"
   },
   "source": [
    "**CheXpert-derived labels** were used for the following reasons:\n",
    "  - Wider clinical coverage (more findings per study captured).\n",
    "  - Multi-label ready (each study has 14 possible findings).\n",
    "  - Includes uncertain cases (better mimics clinical reality).\n",
    "  - CheXpert prioritization logic (positive > uncertain > negative) is more consistent with human diagnostic decision-making.\n",
    "  - Standardized mention extraction patterns (including synonyms and abbreviations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MvYGNWfqZso"
   },
   "source": [
    "The following are the labels extracted using CheXpert:\n",
    "- No Finding\n",
    "- Enlarged Cardiomediastinum\n",
    "- Cardiomegaly\n",
    "- Lung Opacity                                            \n",
    "- Lung Lesion\n",
    "- Edema\n",
    "- Consolidation\n",
    "- Pneumonia\n",
    "- Atelectasis\n",
    "- Pneumothorax\n",
    "- Pleural Effusion\n",
    "- Pleural Other\n",
    "- Fracture\n",
    "- Support Devices\n",
    "\n",
    "\n",
    "| Label Value | Meaning       | Interpretation                                    |\n",
    "| ----------- | ------------- | ------------------------------------------------- |\n",
    "| `1.0`       | Positive      | Condition is clearly **present**                 |\n",
    "| `0.0`       | Negative      | Condition is clearly **absent**                   |\n",
    "| `-1.0`      | Uncertain     | Radiologist **suspects** condition but isn't sure |\n",
    "| `null`      | Not mentioned | No statement about the condition                  |\n",
    "\n",
    "\n",
    "There are over 14 view positions for the chest X-rays in the dataset.\n",
    "\n",
    "For chest X-rays, **PA (Posteroanterior)** and **AP (Anteroposterior)** are the most common and diagnostically rich frontal views:\n",
    "\n",
    "- **PA** is the standard in ambulatory settings:\n",
    "  - The patient stands facing the detector.\n",
    "  - Results in a clearer and less magnified heart silhouette.\n",
    "\n",
    "- **AP** is often used for bedridden or ICU patients:\n",
    "  - Taken with the detector behind the patient.\n",
    "  - More prone to artifacts, but still interpretable.\n",
    "\n",
    "These views are preferred because:\n",
    "\n",
    "- They provide a **full frontal projection** of the chest.\n",
    "- They are **easier to learn from** due to greater dataset availability.\n",
    "- They offer **more consistent anatomical display** across patients.\n",
    "- They are **commonly labeled** as part of “normal” or “abnormal” classes in training datasets.\n",
    "\n",
    "By **restricting training to PA/AP views**, we:\n",
    "- **Reduce variability** caused by pose or projection differences.\n",
    "- Help the model **focus on pathology**, rather than view-dependent artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z6FUx7DyKtZD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import numpy as np\n",
    "# For local environment, use Application Default Credentials\n",
    "# Make sure you've run: gcloud auth application-default login\n",
    "# or set GOOGLE_APPLICATION_CREDENTIALS environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "YGaxl0lILhIc",
    "outputId": "8dd9f926-4c02-4725-e7c6-388f35351f4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged_Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung_Lesion</th>\n",
       "      <th>...</th>\n",
       "      <th>Pleural_Effusion</th>\n",
       "      <th>Pleural_Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support_Devices</th>\n",
       "      <th>split</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>study_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14887088</td>\n",
       "      <td>54257662</td>\n",
       "      <td>1bc85033-355accce-e8d0ed50-78188cd3-dac92e86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>AP</td>\n",
       "      <td>2539</td>\n",
       "      <td>776</td>\n",
       "      <td>2135-01-27 04:49:44.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18650767</td>\n",
       "      <td>54780106</td>\n",
       "      <td>7920918a-6b7415f5-f5b6f7d5-815bb396-c6702eb3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>PA</td>\n",
       "      <td>1504</td>\n",
       "      <td>1188</td>\n",
       "      <td>2131-09-14 22:14:49.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11548266</td>\n",
       "      <td>59905684</td>\n",
       "      <td>95bf2c9c-fd2e6da5-fe82e5db-032420dd-d4daa45c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>PA</td>\n",
       "      <td>1713</td>\n",
       "      <td>1309</td>\n",
       "      <td>2129-04-20 13:37:47.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13191147</td>\n",
       "      <td>55483625</td>\n",
       "      <td>b9cf3249-939bd85e-aaf9795b-d2c0a201-3c0d322c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>PA</td>\n",
       "      <td>2000</td>\n",
       "      <td>1356</td>\n",
       "      <td>2184-12-08 12:03:51.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13880916</td>\n",
       "      <td>53360233</td>\n",
       "      <td>729183be-b03670e1-35db29c1-356f54ed-94481994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>PA</td>\n",
       "      <td>1986</td>\n",
       "      <td>1380</td>\n",
       "      <td>2170-04-27 12:42:31.124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id                                      dicom_id  \\\n",
       "0    14887088  54257662  1bc85033-355accce-e8d0ed50-78188cd3-dac92e86   \n",
       "1    18650767  54780106  7920918a-6b7415f5-f5b6f7d5-815bb396-c6702eb3   \n",
       "2    11548266  59905684  95bf2c9c-fd2e6da5-fe82e5db-032420dd-d4daa45c   \n",
       "3    13191147  55483625  b9cf3249-939bd85e-aaf9795b-d2c0a201-3c0d322c   \n",
       "4    13880916  53360233  729183be-b03670e1-35db29c1-356f54ed-94481994   \n",
       "\n",
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0          NaN           0.0            0.0    NaN   \n",
       "1          NaN          -1.0            NaN   -1.0   \n",
       "2          NaN           NaN            NaN    NaN   \n",
       "3          NaN           NaN            NaN    0.0   \n",
       "4          NaN           NaN            NaN    NaN   \n",
       "\n",
       "   Enlarged_Cardiomediastinum  Fracture  Lung_Lesion  ...  Pleural_Effusion  \\\n",
       "0                         NaN       NaN          NaN  ...               NaN   \n",
       "1                         NaN       NaN          NaN  ...               NaN   \n",
       "2                         NaN       NaN          NaN  ...               NaN   \n",
       "3                         NaN       1.0          NaN  ...               NaN   \n",
       "4                         NaN       NaN          NaN  ...               NaN   \n",
       "\n",
       "   Pleural_Other  Pneumonia  Pneumothorax  Support_Devices  split  \\\n",
       "0            NaN        NaN           NaN              1.0  train   \n",
       "1            NaN        1.0           NaN              NaN  train   \n",
       "2            NaN        NaN           NaN              NaN  train   \n",
       "3            NaN        NaN           NaN              NaN  train   \n",
       "4            NaN        NaN           NaN              NaN  train   \n",
       "\n",
       "   ViewPosition  Rows Columns           study_datetime  \n",
       "0            AP  2539     776  2135-01-27 04:49:44.968  \n",
       "1            PA  1504    1188  2131-09-14 22:14:49.221  \n",
       "2            PA  1713    1309  2129-04-20 13:37:47.133  \n",
       "3            PA  2000    1356  2184-12-08 12:03:51.120  \n",
       "4            PA  1986    1380  2170-04-27 12:42:31.124  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"filtered_cxr\"\n",
    "file_path = \"cxr\"\n",
    "gcs_path = f\"gs://{bucket_name}/{file_path}\"\n",
    "\n",
    "df = pd.read_csv(gcs_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling images per lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 5000 images for Atelectasis\n",
      "Sampled 5000 images for Cardiomegaly\n",
      "Sampled 5000 images for Consolidation\n",
      "Sampled 5000 images for Edema\n",
      "Sampled 5000 images for Enlarged_Cardiomediastinum\n",
      "Sampled 4277 images for Fracture\n",
      "Sampled 5000 images for Lung_Lesion\n",
      "Sampled 5000 images for Lung_Opacity\n",
      "Sampled 5000 images for Pleural_Effusion\n",
      "Sampled 1449 images for Pleural_Other\n",
      "Sampled 5000 images for Pneumonia\n",
      "Sampled 5000 images for Pneumothorax\n",
      "Sampled 5000 images for Support_Devices\n",
      "Sampled 5000 truly normal images (No_Finding only)\n",
      "\n",
      "Sample reports:\n",
      "Normal cases:\n",
      "- Evidence of support devices is present.\n",
      "- Evidence of support devices is present.\n",
      "- No evidence of consolidation. No evidence of edema. No evidence of enlarged cardiomediastinum. No evidence of pleural effusion. No evidence of pneumothorax. Evidence of support devices is present.\n",
      "\n",
      "Abnormal cases:\n",
      "- Evidence of atelectasis is present.\n",
      "- Evidence of atelectasis is present.\n",
      "- Evidence of atelectasis is present. Evidence of lung opacity is present. Evidence of pleural effusion is present. No evidence of pneumothorax. Evidence of support devices is present.\n",
      "\n",
      "Final dataset: 65726 samples\n",
      "Normal cases (No_Finding=1.0): 6144\n",
      "Abnormal cases: 59582\n"
     ]
    }
   ],
   "source": [
    "label_cols = [\n",
    "'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema',\n",
    "'Enlarged_Cardiomediastinum', 'Fracture', 'Lung_Lesion',\n",
    "'Lung_Opacity', 'No_Finding', 'Pleural_Effusion',\n",
    "'Pleural_Other', 'Pneumonia', 'Pneumothorax', 'Support_Devices'\n",
    "]\n",
    "\n",
    "# Separate No_Finding from pathological conditions\n",
    "pathological_cols = [col for col in label_cols if col != 'No_Finding']\n",
    "\n",
    "# Filter to rows with at least one positive label (including No_Finding)\n",
    "df_labels = df.copy()\n",
    "df_labels = df_labels[df_labels[label_cols].notna().any(axis=1)]\n",
    "\n",
    "# Container for sampled entries\n",
    "sampled_rows = []\n",
    "\n",
    "# Keep track of already used dicom_ids\n",
    "used_dicom_ids = set()\n",
    "\n",
    "# Sampling 5000 per pathological label (excluding No_Finding)\n",
    "for label in pathological_cols:\n",
    "    label_df = df_labels[df_labels[label] == 1.0]\n",
    "    # Avoid reusing the same dicom_id unless unavoidable\n",
    "    label_df = label_df[~label_df['dicom_id'].isin(used_dicom_ids)]\n",
    "    # Take up to 5000\n",
    "    sample = label_df.sample(n=min(5000, len(label_df)), random_state=33)\n",
    "    # Track used dicoms\n",
    "    used_dicom_ids.update(sample['dicom_id'])\n",
    "    sampled_rows.append(sample)\n",
    "    print(f\"Sampled {len(sample)} images for {label}\")\n",
    "\n",
    "# Separately handle No_Finding (normal cases)\n",
    "no_finding_df = df_labels[df_labels['No_Finding'] == 1.0]\n",
    "# For No_Finding, we want cases that are ONLY normal (no other positive findings)\n",
    "truly_normal = no_finding_df[\n",
    "    (no_finding_df[pathological_cols] != 1.0).all(axis=1) |  # No positive pathological findings\n",
    "    no_finding_df[pathological_cols].isna().all(axis=1)      # Or all pathological labels are NaN\n",
    "]\n",
    "\n",
    "# Avoid reusing dicom_ids\n",
    "truly_normal = truly_normal[~truly_normal['dicom_id'].isin(used_dicom_ids)]\n",
    "normal_sample = truly_normal.sample(n=min(5000, len(truly_normal)), random_state=33)\n",
    "used_dicom_ids.update(normal_sample['dicom_id'])\n",
    "sampled_rows.append(normal_sample)\n",
    "print(f\"Sampled {len(normal_sample)} truly normal images (No_Finding only)\")\n",
    "\n",
    "# Combine all sampled subsets\n",
    "sampled_df = pd.concat(sampled_rows, ignore_index=True)\n",
    "\n",
    "def label_to_text(label, condition):\n",
    "    if pd.isna(label):\n",
    "        return None\n",
    "    elif condition == 'No_Finding':\n",
    "        # Special handling for No_Finding\n",
    "        if label == 1.0:\n",
    "            return \"The chest X-ray appears normal with no acute findings.\"\n",
    "        elif label == 0.0:\n",
    "            return \"Abnormal findings are present.\"  # If No_Finding is explicitly negative\n",
    "        elif label == -1.0:\n",
    "            return \"The image quality or findings are uncertain.\"\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        # Handle pathological conditions\n",
    "        if label == 1.0:\n",
    "            return f\"Evidence of {condition.lower().replace('_', ' ')} is present.\"\n",
    "        elif label == 0.0:\n",
    "            return f\"No evidence of {condition.lower().replace('_', ' ')}.\"\n",
    "        elif label == -1.0:\n",
    "            return f\"There is suspicion of {condition.lower().replace('_', ' ')}.\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def create_report(row):\n",
    "    sentences = []\n",
    "    \n",
    "    # Check if this is a normal case (No_Finding = 1.0 and no positive pathological findings)\n",
    "    is_normal = (row['No_Finding'] == 1.0 and \n",
    "                 (row[pathological_cols] != 1.0).all())\n",
    "    \n",
    "    if is_normal:\n",
    "        # For normal cases, just use the No_Finding description\n",
    "        normal_sentence = label_to_text(row['No_Finding'], 'No_Finding')\n",
    "        if normal_sentence:\n",
    "            sentences.append(normal_sentence)\n",
    "    else:\n",
    "        # For abnormal cases, describe all findings except No_Finding\n",
    "        for condition in pathological_cols:\n",
    "            sentence = label_to_text(row[condition], condition)\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "        \n",
    "        # Only mention No_Finding if it's explicitly negative (meaning abnormal)\n",
    "        if row['No_Finding'] == 0.0:\n",
    "            no_finding_sentence = label_to_text(row['No_Finding'], 'No_Finding')\n",
    "            if no_finding_sentence:\n",
    "                sentences.insert(0, no_finding_sentence)  # Put at beginning\n",
    "    \n",
    "    return \" \".join(sentences)\n",
    "\n",
    "# Add new column to the DataFrame\n",
    "sampled_df[\"mini_report\"] = sampled_df.apply(create_report, axis=1)\n",
    "\n",
    "# Print some examples\n",
    "print(\"\\nSample reports:\")\n",
    "print(\"Normal cases:\")\n",
    "normal_cases = sampled_df[sampled_df['No_Finding'] == 1.0].head(3)\n",
    "for idx, row in normal_cases.iterrows():\n",
    "    print(f\"- {row['mini_report']}\")\n",
    "\n",
    "print(\"\\nAbnormal cases:\")\n",
    "abnormal_cases = sampled_df[sampled_df['No_Finding'] != 1.0].head(3)\n",
    "for idx, row in abnormal_cases.iterrows():\n",
    "    print(f\"- {row['mini_report']}\")\n",
    "\n",
    "# Save final result\n",
    "sampled_df.to_csv('sampled_5000_per_label.csv', index=False)\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(sampled_df)} samples\")\n",
    "print(f\"Normal cases (No_Finding=1.0): {len(sampled_df[sampled_df['No_Finding'] == 1.0])}\")\n",
    "print(f\"Abnormal cases: {len(sampled_df[sampled_df['No_Finding'] != 1.0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65726, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged_Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung_Lesion</th>\n",
       "      <th>...</th>\n",
       "      <th>Pleural_Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support_Devices</th>\n",
       "      <th>split</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>study_datetime</th>\n",
       "      <th>mini_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18310719</td>\n",
       "      <td>57997889</td>\n",
       "      <td>84eb7e34-12b4cdcf-04196ef9-a5d6e59d-3d17fafc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>AP</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>2129-05-30 17:47:45.468</td>\n",
       "      <td>Evidence of atelectasis is present.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14004638</td>\n",
       "      <td>54797919</td>\n",
       "      <td>110e4fe4-2b4d6b84-14687e5f-877c71ea-d469285a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>AP</td>\n",
       "      <td>3050</td>\n",
       "      <td>2539</td>\n",
       "      <td>2156-01-24 08:14:06.953</td>\n",
       "      <td>Evidence of atelectasis is present.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13233757</td>\n",
       "      <td>56501945</td>\n",
       "      <td>43eaf4e8-7069e8c1-472726df-b9acc888-c8069f09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>AP</td>\n",
       "      <td>2539</td>\n",
       "      <td>3050</td>\n",
       "      <td>2156-08-30 05:51:23.468</td>\n",
       "      <td>Evidence of atelectasis is present. Evidence o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16444272</td>\n",
       "      <td>54476134</td>\n",
       "      <td>32e6ec27-1022a80a-37c2af58-4415c8de-d3da40ef</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>2146-02-09 23:01:11.437</td>\n",
       "      <td>Evidence of atelectasis is present. Evidence o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17372922</td>\n",
       "      <td>51457365</td>\n",
       "      <td>796cef17-0b455d0e-56288df5-80097fde-f090b2ba</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>AP</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>2156-10-05 20:30:24.765</td>\n",
       "      <td>Evidence of atelectasis is present. No evidenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id                                      dicom_id  \\\n",
       "0    18310719  57997889  84eb7e34-12b4cdcf-04196ef9-a5d6e59d-3d17fafc   \n",
       "1    14004638  54797919  110e4fe4-2b4d6b84-14687e5f-877c71ea-d469285a   \n",
       "2    13233757  56501945  43eaf4e8-7069e8c1-472726df-b9acc888-c8069f09   \n",
       "3    16444272  54476134  32e6ec27-1022a80a-37c2af58-4415c8de-d3da40ef   \n",
       "4    17372922  51457365  796cef17-0b455d0e-56288df5-80097fde-f090b2ba   \n",
       "\n",
       "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0          1.0           NaN            NaN    NaN   \n",
       "1          1.0           NaN            NaN    NaN   \n",
       "2          1.0           NaN            NaN    NaN   \n",
       "3          1.0           NaN            NaN    1.0   \n",
       "4          1.0           NaN            NaN    0.0   \n",
       "\n",
       "   Enlarged_Cardiomediastinum  Fracture  Lung_Lesion  ...  Pleural_Other  \\\n",
       "0                         NaN       NaN          NaN  ...            NaN   \n",
       "1                         NaN       NaN          NaN  ...            NaN   \n",
       "2                         NaN       NaN          NaN  ...            NaN   \n",
       "3                         NaN       NaN          NaN  ...            NaN   \n",
       "4                         NaN       NaN          NaN  ...            NaN   \n",
       "\n",
       "   Pneumonia  Pneumothorax  Support_Devices  split  ViewPosition  Rows  \\\n",
       "0        NaN           NaN              NaN  train            AP  2544   \n",
       "1        NaN           NaN              NaN  train            AP  3050   \n",
       "2        NaN           0.0              1.0  train            AP  2539   \n",
       "3        NaN           NaN              NaN  train            PA  3056   \n",
       "4        NaN           NaN              1.0  train            AP  2544   \n",
       "\n",
       "  Columns           study_datetime  \\\n",
       "0    3056  2129-05-30 17:47:45.468   \n",
       "1    2539  2156-01-24 08:14:06.953   \n",
       "2    3050  2156-08-30 05:51:23.468   \n",
       "3    2544  2146-02-09 23:01:11.437   \n",
       "4    3056  2156-10-05 20:30:24.765   \n",
       "\n",
       "                                         mini_report  \n",
       "0                Evidence of atelectasis is present.  \n",
       "1                Evidence of atelectasis is present.  \n",
       "2  Evidence of atelectasis is present. Evidence o...  \n",
       "3  Evidence of atelectasis is present. Evidence o...  \n",
       "4  Evidence of atelectasis is present. No evidenc...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (65726, 23)\n",
      "Stratification labels shape: (65726, 14)\n",
      "Train+Val set shape: (52527, 23)\n",
      "Test set shape: (13199, 23)\n",
      "\n",
      "Final split sizes:\n",
      "Train set: 39422 samples (60.0%)\n",
      "Val set: 13105 samples (19.9%)\n",
      "Test set: 13199 samples (20.1%)\n",
      "\n",
      "Train label distribution:\n",
      "  Atelectasis: 11590/14045 (82.5%)\n",
      "  Cardiomegaly: 10789/15197 (71.0%)\n",
      "  Consolidation: 4578/6741 (67.9%)\n",
      "  Edema: 7886/14792 (53.3%)\n",
      "  Enlarged_Cardiomediastinum: 3847/7014 (54.8%)\n",
      "  Fracture: 2869/3024 (94.9%)\n",
      "  Lung_Lesion: 3628/3932 (92.3%)\n",
      "  Lung_Opacity: 13383/14551 (92.0%)\n",
      "  No_Finding: 3686/3686 (100.0%)\n",
      "  Pleural_Effusion: 15029/20720 (72.5%)\n",
      "  Pleural_Other: 1251/1396 (89.6%)\n",
      "  Pneumonia: 5921/12631 (46.9%)\n",
      "  Pneumothorax: 4799/14842 (32.3%)\n",
      "  Support_Devices: 16847/17587 (95.8%)\n",
      "\n",
      "Validation label distribution:\n",
      "  Atelectasis: 3846/4677 (82.2%)\n",
      "  Cardiomegaly: 3615/5117 (70.6%)\n",
      "  Consolidation: 1499/2234 (67.1%)\n",
      "  Edema: 2663/4928 (54.0%)\n",
      "  Enlarged_Cardiomediastinum: 1313/2357 (55.7%)\n",
      "  Fracture: 953/1008 (94.5%)\n",
      "  Lung_Lesion: 1223/1311 (93.3%)\n",
      "  Lung_Opacity: 4470/4847 (92.2%)\n",
      "  No_Finding: 1229/1229 (100.0%)\n",
      "  Pleural_Effusion: 4993/7012 (71.2%)\n",
      "  Pleural_Other: 415/466 (89.1%)\n",
      "  Pneumonia: 1987/4246 (46.8%)\n",
      "  Pneumothorax: 1607/4945 (32.5%)\n",
      "  Support_Devices: 5601/5846 (95.8%)\n",
      "\n",
      "Test label distribution:\n",
      "  Atelectasis: 3872/4684 (82.7%)\n",
      "  Cardiomegaly: 3586/5028 (71.3%)\n",
      "  Consolidation: 1493/2252 (66.3%)\n",
      "  Edema: 2586/4921 (52.6%)\n",
      "  Enlarged_Cardiomediastinum: 1263/2303 (54.8%)\n",
      "  Fracture: 959/1003 (95.6%)\n",
      "  Lung_Lesion: 1209/1309 (92.4%)\n",
      "  Lung_Opacity: 4472/4848 (92.2%)\n",
      "  No_Finding: 1229/1229 (100.0%)\n",
      "  Pleural_Effusion: 5006/6941 (72.1%)\n",
      "  Pleural_Other: 417/462 (90.3%)\n",
      "  Pneumonia: 2036/4202 (48.5%)\n",
      "  Pneumothorax: 1603/4916 (32.6%)\n",
      "  Support_Devices: 5619/5845 (96.1%)\n",
      "\n",
      "Saved splits to CSV files:\n",
      "- train_split.csv: 39422 samples\n",
      "- val_split.csv: 13105 samples\n",
      "- test_split.csv: 13199 samples\n"
     ]
    }
   ],
   "source": [
    "# Create stratification labels matrix (only using the 14 label columns)\n",
    "# Replace NaN with 0 for stratification purposes\n",
    "stratify_labels = sampled_df[label_cols].fillna(0).values\n",
    "\n",
    "print(f\"Original dataset shape: {sampled_df.shape}\")\n",
    "print(f\"Stratification labels shape: {stratify_labels.shape}\")\n",
    "\n",
    "# First split: separate out test set (20%)\n",
    "splitter_test = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=33)\n",
    "train_val_idx, test_idx = next(splitter_test.split(sampled_df, stratify_labels))\n",
    "\n",
    "# Get train+val and test sets\n",
    "train_val_df = sampled_df.iloc[train_val_idx].copy()\n",
    "test_df = sampled_df.iloc[test_idx].copy()\n",
    "train_val_labels = stratify_labels[train_val_idx]\n",
    "\n",
    "print(f\"Train+Val set shape: {train_val_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Second split: split train+val into train (60% of original) and val (20% of original)\n",
    "# This means val will be 0.25 of the train_val set (0.25 * 0.8 = 0.2 of original)\n",
    "splitter_val = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=33)\n",
    "train_idx, val_idx = next(splitter_val.split(train_val_df, train_val_labels))\n",
    "\n",
    "# Get final train and val sets\n",
    "train_df = train_val_df.iloc[train_idx].copy()\n",
    "val_df = train_val_df.iloc[val_idx].copy()\n",
    "\n",
    "print(f\"\\nFinal split sizes:\")\n",
    "print(f\"Train set: {train_df.shape[0]} samples ({train_df.shape[0]/len(sampled_df)*100:.1f}%)\")\n",
    "print(f\"Val set: {val_df.shape[0]} samples ({val_df.shape[0]/len(sampled_df)*100:.1f}%)\")\n",
    "print(f\"Test set: {test_df.shape[0]} samples ({test_df.shape[0]/len(sampled_df)*100:.1f}%)\")\n",
    "\n",
    "def print_label_distribution(df, split_name):\n",
    "    print(f\"\\n{split_name} label distribution:\")\n",
    "    for label in label_cols:\n",
    "        positive_count = (df[label] == 1.0).sum()\n",
    "        total_count = df[label].notna().sum()\n",
    "        if total_count > 0:\n",
    "            percentage = positive_count / total_count * 100\n",
    "            print(f\"  {label}: {positive_count}/{total_count} ({percentage:.1f}%)\")\n",
    "\n",
    "print_label_distribution(train_df, \"Train\")\n",
    "print_label_distribution(val_df, \"Validation\")\n",
    "print_label_distribution(test_df, \"Test\")\n",
    "\n",
    "# Save the splits\n",
    "train_df.to_csv('train_split.csv', index=False)\n",
    "val_df.to_csv('val_split.csv', index=False)\n",
    "test_df.to_csv('test_split.csv', index=False)\n",
    "\n",
    "print(f\"\\nSaved splits to CSV files:\")\n",
    "print(f\"- train_split.csv: {len(train_df)} samples\")\n",
    "print(f\"- val_split.csv: {len(val_df)} samples\") \n",
    "print(f\"- test_split.csv: {len(test_df)} samples\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
